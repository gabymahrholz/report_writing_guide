{
  "hash": "011a099fb925904d92eeec89f89e32ea",
  "result": {
    "markdown": "# Methods {.unnumbered}\n\nThe general structure of a methods section is pretty similar regardless of whether you are collecting data or choosing to utilise already existing datasets to answer your research question. However, information relating to participants and data collection in primary research is substituted by information about the original dataset and the selection process for secondary data analysis. \n\n**For primary data collection**\n\n* [Research design overview](methods.qmd#sec-design)\n* [Participants recruitment](methods.qmd#sec-participants)\n* [Data collection](methods.qmd#sec-datacollection)\n* [Ethics](methods.qmd#sec-ethics)\n* [Reflexivity](methods.qmd#sec-reflexivity)\n* [Data analysis](methods.qmd#sec-analysis)\n\n\n**For secondary data analysis**\n\n* [Research design overview](methods.qmd#sec-design)\n* [Secondary data](methods.qmd#sec-secondary)\n* [Data selection](methods.qmd#sec-selection)\n* [Ethics](methods.qmd#sec-ethics)\n* [Reflexivity](methods.qmd#sec-reflexivity)\n* [Data analysis](methods.qmd#sec-analysis)\n\n\n::: {.callout-important}\nThe headings are interlaced in the following sections. Sections applicable to only primary or secondary data analysis approaches are specifically labelled. If there is a specific label attached, sections apply to both methods equally.\n:::\n\n## Research design overview {#sec-design}\n\nIn this section, you want to address your questions such as:\n\n* Why qualitative methods?\n* Justification of the chosen design: Why is Thematic Analysis (TA) the best framework for your research question?\n* Specify the theoretical underpinnings of TA (e.g., experiential vs critical; theories of language; epistemology/ontology; deductive vs inductive; semantic vs latent)\n* Justification on data collection methods: Why focus groups/ interviews/ social media sites/ UK data service/ ...?\n\n::: {.callout-note}\nWhy qualitative methods can be covered briefly you have already addressed this as part of your rationale in the introduction.\n:::\n\n::: {.callout-note}\nThe justification for data collection methods could also be moved to data collection if you think it would be more logical to place it there.\n:::\n\n\n### Why TA?\nThis is a really difficult section to get right. In [this critical review (p. 703, point 3)](https://doi.org/10.1080/17437199.2022.2161594){target=\"_blank\"}, Braun and Clarke mention that approximately half of the studies they reviewed did not provide any rationale that justifies the use of TA. Or descriptions were super generic that they could be easily applied to any other qual methodology.\n\nBraun and Clarke suggest that best practice would be to include a clear and specific rationale for the use of (the particular form of) TA, connected to the research question, theory, and/or context. For example, if TA’s flexibility is a selling feature for you, explain how it was utilised and why it was important for your research question.\n\nOne way of justifying could broadly address which [qualitative research “camp”](#sec-camps) you map onto – experiential or critical. And/or you could refer to **inductive (e.g., data-driven) vs deductive orientations (e.g., theory/researcher-driven) to the data** or whether you focus on **semantic (e.g., surface-level/ explicit meaning) vs latent analysis (implicit meaning) ** (both currently addressed in [Phase 2: Data coding](#sec-phase2)). Another way could be to argue via the [**theoretical underpinnings**]( {#sec-theory). \n\n### Two qualitative research camps {#sec-camps}\n\n**Experiential research** explores the meanings, views, perspectives, experiences and/or practices expressed in the data. Participants’ interpretations are prioritised, accepted and focused on, rather than being used as a basis for analysing something else.\n\n**Critical research** takes an interrogative stance towards the meanings or experiences expressed in the data and uses them to explore some other phenomenon. Typically, it seeks to understand the factors influencing, and the effects of, the particular meanings or representations expressed. It is critical because it doesn’t take data at face value. This means that analysts’ interpretations become more important than participants’.\n\n### Theoretical underpinnings {#sec-theory}\n\n**TA is not a single method**. It is really flexible and can be utilised for **small q** (e.g., qual data with a quant paradigm) and **Big Q** frameworks (e.g., qual data with a qual framework). \n\nThere is a misconception that TA is atheoretical, but because of its flexibility, is super important to define your theoretical underpinnings. You can do this via **Theories of language** and/or **the \"ologies\"**\n\n::: {.callout-caution}\nTheory is complex. It takes time to develop a clear(ish) sense of your Big Theory positions. So be patient and don’t get frustrated if it doesn’t click straight away.\n:::\n\n#### Theories of language\nFor **experiential researchers**, language is a tool for communicating meaning – the words we collect from participants communicate something about their thoughts, feelings and beliefs.\nFor **critical researchers**, language isn’t simply a conduit or a communication tool, but a social practice, one of the main ways in which humans and societies create meaning and realities.\n\nAccording to Stuart Hall (1997), there are 3 different theories of language (as cited in Braun & Clarke, 2022, p. 164)\n\n* **Reflective:** language reflects the true nature of something – it’s like a mirror. A material reality independent of language is assumed to exist and to be revealed through language (**mind-independent truths**; maps onto a **realist** framework).\n* **Intentional:** language is used to convey the speaker’s unique perspective on things, their reality, their truths (moves away from universal meanings and locate meaning within the person; maps onto **critical realist**; **a mind-dependent truth**).\n* **Constructionist** conceptualisations treat language as social and meaning as more malleable and flexible. Meaning is created or constructed in and through language (e.g., the language we use, the ways we talk and write about things). Language here is understood as symbolic, and powerful, rather than neutral; as active, rather than passive (maps onto **relativism**).\n\n#### The \"Ologies\": Epistemology and Ontology\nThe dreaded “Ologies” – not gonna lie, this is pretty philosophical and tough to get your head around. Additionally, it’s not helpful that there are a variety of similar concepts floating about. Here we are keeping to the holy writings that are Braun and Clarke (2022) – trying to keep it brief.\n\n**Ontology** refers to the **Theory of reality**\nExtremely simplified, ask yourself “is there a reality that exists separately from our research\npractice?”. If the answer is:\n* “Well of course there is” – this is captured by an ontological position known as **realism** (assumed a single truth and it can be discovered; small q; maps onto (post)positivist epistemology).\n* “Um yes but also no” – this is captured by a position known as **critical realism** (reality and representations of reality are *not* the same; they think the truth is out there but cannot be accessed directly)\n* “Definitely not, how naïve are you?” – this is captured by a position known as **relativism** (Big Q; maps onto Constructionism; language is used to create truth).\n\n::: {.callout-tip}\nFor a deep dive into ontology, read Braun and Clarke (2022), pages 167-175.\n:::\n\n**Epistemology** refers to the **theories of knowledge**.\n\nIt’s basically the question of how knowledge is generated. What do we think is possible to know? What modes of information do we trust as real, true, valid sources of information?\nHere we have 3 types that map broadly onto the 3 ontological positions:\n* **(Post)positivism** recognises observations are selective, and our perception of the world is partial; reality can only ever be understood imperfectly, and from a situated position. However, objective knowledge is the ideal (uses research practices that aim for objectivity, e.g., coding-reliability; small q framework).\n* **Contextualism** knowledge *cannot* be separated from the knower, and the researcher’s values and practices inevitably shape the knowledge they produce (maps broadly onto a critical realist ontology; Big Q; but).\n* **Constructionism** research practices *produce* rather than reveal evidence. A focus on language is central to constructionist research. They theorise that the way people write or talk creates realities rather than simply reflecting them. The researcher is like an artist or a storyteller who creates “something” but that “something” has to ‘make sense’ within existing systems of meaning.\n\n::: {.callout-tip}\nIf this has not blown your mind entirely, read Braun and Clarke (2022), page 184-186 the section titled **Checking out the view from the houses of epistemology**. It’s a very interesting metaphor trying to relate these 3 epistemological positions to “being in a house, looking through a window at some flowers”\n:::\n\n::: {.callout-tip}\nFor a deep dive into epistemology, read Braun and Clarke (2022), pages 175-188.\n:::\n\n\nTo sum up, basically, you want to place yourself explicitly within this flexible framework. By now, you may have noticed that these different variations of reflexive TA kind of cluster together – **experiential**, **(post)positivism**, **semantic**, and **inductive** approaches on one side and **critical**, **constructionist** , **latent**, and **deductive** approaches on the other. But these different approaches are not mutually exclusive, they are actually more on a spectrum (see @img-variations).\n \n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![The variations of reflexive TA (Braun & Clarke, p. 10](images/variations.PNG){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n::: {.callout-note}\n## Good and bad examples for \"Why TA\"\nThere are also some examples in [Braun and Clarke (2022)]( https://go.exlibris.link/4s9L4DWP) for a generic justification (Table 5.1, p. 123) and some examples from published papers (Table 5.2, p. 124) \n\nThe rationale for “why TA” can actually be quite brief (see for example, [Rance et al., 2017](https://doi.org/10.1177/1359105315609088){target=\"_blank\"})\n:::\n\n## Participants recruitment (primary data collection only) {#sec-participants}\n\nDescribe your participants. Cover aspects like:\n\n* How many participants and who were they?\n* Provide a table with pseudonyms, age, gender, nationality\n* Why were these participants considered right for your study aim?\n\n\n## Data collection (primary data collection only) {#sec-datacollection} \nIn this section, you want to describe…\n\n* What materials you used (e.g., demographics questionnaires; focus group schedule; interview schedule; etc.)\n* What information was provided ahead of the focus group/interview (e.g., did they receive the questions in advance)\n* How the focus groups/interviews were recorded\n* How long the focus groups/interviews took\n\n\n## Secondary data (secondary data only) {#sec-secondary}\n\nHere you want to describe the original study/dataset briefly to give the reader context about their data collection. You want to address questions like:\n\n* What was the original study about? \n* Who conducted it? \n* Where did you get the data from? (make sure to cite the original study in APA 7 format) \n* What methodology did they use?\n* How many interviews/ focus groups, etc. did they conduct? \n* Who were their participants and what were they asked about?\n\n::: {.callout-caution}\nYou can only provide as much information as you have available. This section might be quite short (e.g., if you have data from the UK Data Service) or substantial (e.g., with a published paper).\n:::\n\n## Data selection (secondary data only) {#sec-selection}\n\nDescribe your procedure for choosing your final data set. \n\n* If you included all the data from the original study, feel free to combine the sections Secondary data and Data selection, but relabel the heading. \n* If you are using a subsection of the original dataset, explain how many FGs/interviews/... you chose, and the reasons why you chose the specific ones you decided to use for your analysis. Be transparent about how you narrowed down the original dataset.\n\n\n## Ethics {#sec-ethics}\n\n### Primary data collection\n\n* Mention that your Ethics were approved and state by whom (add application number in brackets for primary data collection)\n* Address \"formal\" ethics procedures like gathering consent\n* You might also want to address more non-formal procedures like rapport building [unless you already included it elsewhere]\n\n### Secondary data collection\n\nThe information you are able to provide in this section will depend on the information made available within the dataset. Some things you might want to comment on: anonymisation procedures (e.g. has information been replaced or redacted), rapport building, information/ consent/ debrief, and consent as a process. You will only be able to include information that has been made available in the dataset, so do not worry if you do not know a lot of details.\n\n\n## Reflexivity {#sec-reflexivity}\n\nAccording to Braun and Clarke (2022), reflexivity involves the practice of critical reflection on your role as a researcher, and your research practice and process. We need to critically interrogate what we do, how and why we do it, and the impacts and influences of this on our research.\n\nReflexivity isn’t all navel-gazing and just thinking about yourself; it’s also about the knowledge we produce from research and how we produce it. British feminist psychologist Sue Wilkinson (1988) offered a useful distinction between:\n\n* Personal reflexivity – how the researcher’s values shape their research and the knowledge produced;\n* Functional reflexivity – how the methods and other aspects of design shape the research and knowledge produced; and\n* Disciplinary reflexivity – how academic disciplines shape knowledge production.\n\n::: {.callout-tip}\nThe Braun and Clarke book from 2022 has a great activity on these 3 types to get you started (pp. 16-18, blue box)\n:::\n\n## Data Analysis {#sec-analysis}\n\nIn this section, you want to explain how the data was prepared for the analysis and detail the analysis approach\n\n* Did you use specific software to transcribe? Did you use automatic transcriptions and you fixed them manually, or did you transcribe from scratch?\n* How did you anonymise the data? Did you replace or redact identifiable information? (e.g., were participants given pseudonyms; were any information replaced with broader labels or deleted; etc.)\n* Outline the 6 different phases of the TA analysis approach. \n\n### Phase 1: Dataset familiarisation\n\nAs the label says, you become deeply familiar with the content of your dataset. That means reading and re-reading your transcripts/ sources repeatedly. Take some notes about any analytic ideas or insights you may have, both related to each data item (e.g., interview 1, interview 2, etc.) and the dataset as a whole.\n\n***For the dissertation describe briefly how you familiarised yourself with the data.***\n\n### Phase 2: Data coding {#sec-phase2}\n\nWork systematically through your dataset in a fine-grained way. Identify quotes in the data that are either interesting for and/or relevant to your research question. Try to assign a code label (e.g., a word or a phrase) that is analytically meaningful. You'd want to aim for single-meaning code labels so that grouping them together in the next stage becomes easier. You can do this the old-fashioned way with paper and highlighters or use some funky software like NVIVO. The choice is yours.\n\nWhen coding, pay attention to the orientations to data coding: **inductive (data-driven)** vs **deductive (researcher- or theory-driven)** orientations. They are actually on a spectrum, and in reality, they cannot be 100% one or the other. So it's fine to place your orientation as either **predominantly inductive**, **predominantly deductive** or to have **elements of both**. Whatever you decide on, it needs to fit your purpose and your theoretical framework.\n\nIf you are interested in the experiences, perspectives, and meanings of the participants, you are probably taking more of an inductive approach (aligning with Big Q; experiential qualitative research). Whereas if you let theory guide you in your attempt to make meaning of the data, you'd probably have a more deductive orientation.\n\nA second consideration is the level at which you will code meaning – semantic vs latent coding. **Semantic codes** capture explicitly expressed meaning; they often stay close to the language of participants or the overt meanings of data. **Latent codes** focus on a deeper, more implicit level of meaning. Initial coding tends to be more semantic but might switch to more latent coding the more familiar you become with the data. In practice, it's neither one nor the other, so again, we're talking about a spectrum here.\n\n::: {.callout-important}\nDespite keeping close to the language of the participant when coding semantically, you'd still need to interpret going beyond mere repetition of the participants' words. But more about that in the [Analysis](analysis.qmd) section.\n:::\n\nThe codes are the building blocks for your analysis, which means, you'll probably go through this phase repeatedly to refine your code labels.\n\n***In your dissertation, explain your orientation to the data (inductive/deductive) and the level of coding (semantic/latent). This could also be part of your rationale as to “Why TA”.***\n\n\n### Phase 3: Initial theme generation\n\nA theme in reflexive TA is a pattern of shared meaning organised around a central concept.\n\nWhat you are aiming for are cohesive self-contained units of meaning in each theme. The participants will have expressed similar ideas but perhaps used different examples or different contexts. There should be no contradictions within each theme unless your theme is about the contradiction of viewpoints or the tension that arises between them.\n\nIn phase 3, think about how you can group your code labels together. You will probably not be able to use all code labels, and that is totally fine. When Wil and I did our initial theme generation phase, we printed out all code labels, cut them out with scissors, and moved them around 5 different whiteboards (held up with magnets) until they felt about right. \n\nSome labels will group together more easily than others. You will probably end up with a lot of potential themes and not all of them will survive until the end. So don't get too attached to these initial themes!!! I promise you, it will *all* change in phase 4 (or 5 or 6) - muahahaha. It may also happen that your initial codes were too broad and you would have to break them up (again, has to do with becoming more familiar with the data and getting a better understanding of what it all means). If you are lucky, one of these broad codes may actually be a theme. You'll never know. Bottom line is theme generation is messy and will take some time.\n\n\n### Phase 4: Theme development and review\n\nIn phase 4, you want to review the initial themes from phase 3 and revise them by re-engaging with *all* the coded data extracts, and the entire dataset. Make sure that each theme has its own boundaries and that themes don't leak into each other. If that happens, it's probably best to go back to phase 3 or even 2. Don't fret if that happens, it's all part of the process.\n\nIt's also time to check whether your themes are coherent. If they are too diverse, ask yourself whether they might be subthemes of an overarching theme, or parts of different themes altogether.\n\nWhat you want to do is tell a compelling story that addresses the research question and doesn't take you too far away from the data. You need enough meaningful quotes to evidence the theme, but it's also not about numerical frequency (i.e., x number of people said the same word). It's about the theme conveying something important and meaningful for your research question. \n\nOnce you feel you have a set of distinct themes that work in relation to the coded data extracts AND tell a good story, go back to check whether your themes fit in the entire dataset. Still be prepared to let things go.\n\n***In the dissertation, you want to describe the process of how you arrived at the final themes (e.g., phases 3 and 4). It's ok to describe them together since you can expect these 2 phases to interweave quite a bit.***\n\n\n\n\n### Phase 5: Theme refining, defining and naming \n\n### Theme 6: Writing up\n\n::: {.callout-caution}\n## Personalise your 6 TA phases\nThe 6 phases are not sequential steps and they are not intended to be. So don't just copy and paste these phases, personalise this section. Tell the reader exactly how you applied them (see Braun & Clarke, 2022, pp. 35-36, blue box).\n:::\n\n## Keep in mind\n\nThere is some degree of flexibility in the methods section. There are a few things that could be moved about, for example, you could talk about the \"non-formal\" part of ethics either in Ethics or Data collection. Likewise, you could justify the reason for your specific data collection approach in Data collection rather than in Research design overview. You need to decide where information needs to be placed to make the most sense, but the key thing is try and avoid repetition.\n\n\n## Where to find secondary data\n\n* [UK Data Service](https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=851540){target=\"_blank\"}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}